{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca17d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "#model= keras.Sequential([keras.layers.Dense(units=1 , input_shape=[1])])\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bda31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cba99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 26.0070\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.7560\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16.6188\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.3578\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7865\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.7577\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1561\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8905\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8894\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0966\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4677\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9679\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5698\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2517\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9968\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7916\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6256\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4906\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3800\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2887\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2128\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1489\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0947\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0481\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0076\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9720\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9403\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9117\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8857\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8618\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8396\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8188\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7992\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7806\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7629\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7458\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7295\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7136\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6983\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6835\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6690\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6549\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6412\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6279\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6148\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6021\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5896\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5774\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5655\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5538\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5424\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5312\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5203\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5096\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4991\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4889\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4788\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4690\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4593\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4499\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4406\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4316\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4227\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4140\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4055\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3972\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3890\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3811\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3732\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3656\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3580\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3507\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3435\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3364\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3295\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3228\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3161\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3096\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3033\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2970\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2909\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.2850\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2791\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2734\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2678\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2623\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2569\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2516\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2464\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2414\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2364\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2316\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2268\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2221\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2176\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2131\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2087\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2044\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2002\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1961\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1921\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1882\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1843\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1805\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1768\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1732\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1696\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1661\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1627\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1594\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1561\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1529\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1498\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1467\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1437\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1407\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1378\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1350\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.1322\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1295\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1268\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1242\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1217\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1192\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1167\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1143\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1120\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1097\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1074\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1052\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1031\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1010\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0989\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0968\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0949\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0929\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0910\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0891\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0873\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0838\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0820\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0803\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0787\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0771\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0739\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0724\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0709\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0695\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0681\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0667\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0653\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0639\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0626\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0613\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0589\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0576\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0565\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0542\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0531\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0520\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0498\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0488\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0478\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0468\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0449\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0440\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0431\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0422\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0405\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0397\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0389\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0381\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0373\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0365\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0350\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0343\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0336\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0329\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0322\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0316\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0309\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0303\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0297\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0291\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0285\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0279\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0273\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0267\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0262\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0257\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0251\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0246\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0236\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0231\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0227\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0222\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0217\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0200\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0196\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0192\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0188\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0184\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0177\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0169\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0147\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0138\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0132\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0129\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0127\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0124\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0122\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0119\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0112\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0110\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0107\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0105\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0101\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0091\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0085\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0084\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0080\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0077\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0075\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0074\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0072\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0067\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0065\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0064\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0058\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0053\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0052\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0051\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0047\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0045\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0034\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0031\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0030\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0030\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0027\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0024\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.0014\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8648e-04\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6621e-04\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4637e-04\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2693e-04\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0789e-04\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8924e-04\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7097e-04\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5308e-04\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3556e-04\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1840e-04\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0158e-04\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8512e-04\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6899e-04\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5320e-04\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3773e-04\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2257e-04\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0773e-04\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9319e-04\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7895e-04\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6501e-04\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5135e-04\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.3797e-04\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2486e-04\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1203e-04\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9946e-04\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8715e-04\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7509e-04\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6328e-04\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5171e-04\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4037e-04\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2928e-04\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1840e-04\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0776e-04\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.9733e-04\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8711e-04\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7710e-04\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6730e-04\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5771e-04\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.4830e-04\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 4.3909e-04\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3008e-04\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2124e-04\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1259e-04\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0412e-04\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9581e-04\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8768e-04\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7972e-04\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7192e-04\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6428e-04\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5680e-04\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4947e-04\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4229e-04\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3526e-04\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.2837e-04\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2163e-04\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.1502e-04\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0855e-04\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0221e-04\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9601e-04\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 2.8992e-04\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8397e-04\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7814e-04\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7243e-04\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6683e-04\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6135e-04\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5598e-04\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5072e-04\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4557e-04\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4053e-04\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3559e-04\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3075e-04\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2601e-04\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2137e-04\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1682e-04\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1237e-04\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0800e-04\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0373e-04\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9954e-04\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9545e-04\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9143e-04\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8750e-04\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8365e-04\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7988e-04\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7618e-04\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7256e-04\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6902e-04\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6555e-04\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6215e-04\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5882e-04\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5556e-04\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5236e-04\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4923e-04\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4616e-04\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4316e-04\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4022e-04\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3734e-04\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3452e-04\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3176e-04\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2905e-04\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2640e-04\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2380e-04\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2126e-04\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1877e-04\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1633e-04\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1394e-04\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1160e-04\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0931e-04\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0706e-04\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0486e-04\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0271e-04\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0060e-04\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8534e-05\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6510e-05\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4527e-05\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2585e-05\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0683e-05\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8820e-05\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6997e-05\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5209e-05\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3459e-05\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1744e-05\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0066e-05\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8421e-05\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6810e-05\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5233e-05\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3688e-05\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2173e-05\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0691e-05\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9239e-05\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7817e-05\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6424e-05\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5060e-05\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3723e-05\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2413e-05\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1132e-05\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9876e-05\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.8646e-05\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7441e-05\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6262e-05\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.5106e-05\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3975e-05\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2864e-05\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 5.1780e-05\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.0715e-05\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9674e-05\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8654e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243df319280>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on creer les donnes d'entrainements\n",
    "\n",
    "xs=np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "ys=np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0])\n",
    "model.fit(xs,ys,epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d400fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist= tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images,training_labels), (test_images, test_labels)=fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f547a459",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL:8\n",
      "\n",
      "IMAGE PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   5   0  89 108   0   4   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   6   0  79 138 103   0   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   4   0 186  58  97  83   0   6   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   0 208   0 130 146   0   9   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   7   0  82 185   0  86 217   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   8   0 139 157   0  28 253  43   0   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5   0 177  67   0   0 255 106   0   9   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   2   0   0 194   0   0   0 230 163   0   2   2   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  51 186   0   0   0 194 209   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 135 185   0   0   0 151 240   0   0  12   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 149 146 195 104 198 157   7  42   0 133 242 193 217 142 147   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 169 164 192 144 208 181 143 128 137 147 209 211 182 111 118   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 122 170 191  95 208 172 119 195 183 119 211 215 185 119 114   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  88 150 237 102 224 222 140 179 151 161 221 207 201 136 122   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  77 170 192 177 126 125 238 158 169 222 108 126 221 146  82   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  36 188 189 183 123 176 208 143 133 191 193 136 208 146  93   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 186 195 145 122 180 184 172 173 151 169 145 211 143  99   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 174 199 155 131 154 188 192 174 171 157 130 209 149  94   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 166 205 149 123 156 195  94  90 161 161 135 205 163  90   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 179 202 163 131 154 164 124 149 138 171 145 208 161  92   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 166 200 167 129 151 174  94  85 151 163 145 217 158  80   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 174 200 171 133 149 176 201 174 185 138 131 222 166  87   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 181 198 168 122 172 191 168 186 174 186 139 213 164  97   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1 182 199 163 121 177 219 148 156 197 190 139 219 149 107   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   8 180 201 158 125 128 226 174 141 223 147 125 228 157 110   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   6 161 196 160 120 179 204 136 142 171 183 131 195 159 110   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 188 208 172 155 175 157 201 210 162 186 177 214 181 138   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 123 181 132 113 114 134  93  82 116 109 102 154 118  67   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x243e7803940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#on peut choisir entre 0 et  59999\n",
    "index=57\n",
    "\n",
    "#nb de caractere par ligne pour l'affichage\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "#affiche le nom et le titre\n",
    "print(f'LABEL:{training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "#visualisationn\n",
    "plt.imshow(training_images[index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dee69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "#on normalise l'image\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50064611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function:[[1. 3. 4. 2.]]\n",
      "output to softmax function:[[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      " classe avec la plus grande probabilit:2\n"
     ]
    }
   ],
   "source": [
    "#ce code nous montre l'ide gnrale\n",
    "#il reduit l'entrer de manire a obtenir des mesure de proba\n",
    "#il renvoie ensuite l'indice avec la plus grande proba\n",
    "#ce qui correspond  l'image la plus plausible\n",
    "\n",
    "inputs= np.array([[1.0,3.0,4.0,2.0]])\n",
    "inputs=tf.convert_to_tensor(inputs)\n",
    "inputs\n",
    "print(f'input to softmax function:{inputs.numpy()}')\n",
    "\n",
    "#nourie les entrer de la fonction softmax\n",
    "outputs=tf.keras.activations.softmax(inputs)\n",
    "print(f'output to softmax function:{outputs.numpy()}')\n",
    "\n",
    "#obtient la somme de toutes les valeurs de la fonction softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "#on obtient l'index avec la valelur la plus haute\n",
    "prediction=np.argmax(outputs)\n",
    "print(f' classe avec la plus grande probabilit:{prediction}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d090c8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2003 - accuracy: 0.9241\n",
      "Epoch 2/8\n",
      "1875/1875 [==============================] - 2s 895us/step - loss: 0.1938 - accuracy: 0.9271\n",
      "Epoch 3/8\n",
      "1875/1875 [==============================] - 2s 884us/step - loss: 0.1892 - accuracy: 0.9284\n",
      "Epoch 4/8\n",
      "1875/1875 [==============================] - 2s 887us/step - loss: 0.1853 - accuracy: 0.9299\n",
      "Epoch 5/8\n",
      "1875/1875 [==============================] - 2s 887us/step - loss: 0.1789 - accuracy: 0.9322\n",
      "Epoch 6/8\n",
      "1875/1875 [==============================] - 1s 742us/step - loss: 0.1729 - accuracy: 0.9349\n",
      "Epoch 7/8\n",
      "1875/1875 [==============================] - 1s 686us/step - loss: 0.1704 - accuracy: 0.9359\n",
      "Epoch 8/8\n",
      "1875/1875 [==============================] - 1s 701us/step - loss: 0.1671 - accuracy: 0.9368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243c81b7850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(training_images,training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3919bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3769 - accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37690451741218567, 0.8859999775886536]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67aa6fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.5556498e-11 2.6145857e-14 8.0531413e-17 6.3841456e-21 3.4350536e-13 2.6048863e-07 4.9280250e-11 8.9203333e-04 6.9954397e-16 9.9910766e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34f9e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1846\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0747\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0490\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0342\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0262\n",
      "313/313 [==============================] - 0s 821us/step - loss: 0.0784\n",
      "[3.4695069e-10 7.7928428e-09 5.2459388e-08 3.7188409e-05 4.9366235e-13 5.6561227e-09 8.0372384e-13 9.9996281e-01 6.2093823e-09 3.0086536e-08]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist=tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels)= mnist.load_data()\n",
    "\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model=tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
    "                          tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "                        tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "model.evaluate(test_images, test_labels)\n",
    "classification=model.predict(test_images)\n",
    "print(classification[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719c501",
   "metadata": {},
   "source": [
    "On a changer la densit de la couche par 1024.\n",
    "Ce changement  fortement augmanter le temps d'execution du code car on a augmanter le nombre de calcule.\n",
    "On remarque galement une augmentation de la prcision de la classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faaf524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3008\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.1473\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.1068\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.0846\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 773us/step - loss: 0.0693\n",
      "313/313 [==============================] - 0s 526us/step - loss: 0.0902\n",
      "[6.5556498e-11 2.6145857e-14 8.0531413e-17 6.3841456e-21 3.4350536e-13 2.6048863e-07 4.9280250e-11 8.9203333e-04 6.9954397e-16 9.9910766e-01]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnist=tf.keras.datasets.mnist\n",
    "\n",
    "(training_images, training_labels),(test_images,test_labels)=mnist.load_data()\n",
    "\n",
    "\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model=tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                 tf.keras.layers.Dense(64,activation=tf.nn.relu),\n",
    "                                 tf.keras.layers.Dense(10,activation=tf.nn.softmax)])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.fit(training_images, training_labels,epochs=5)\n",
    "\n",
    "model.evaluate(test_images,test_labels)\n",
    "\n",
    "classification=model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
